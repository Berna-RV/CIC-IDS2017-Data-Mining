{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CICIDS2017 - AdaBoost Multiclass Classifier\n",
    "\n",
    "The preprocessing is the same as in LSTM.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample\n",
    "from math import ceil\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.00586076e-04, 4.42942943e-01, 8.26826827e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [3.01916103e-04, 4.42942943e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [3.02248610e-04, 4.42942943e-01, 8.26826827e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [3.16219702e-01, 9.42335051e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [9.45149941e-01, 9.92141282e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.34898670e-01, 7.19219219e-01, 2.55755756e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfv3 = pd.read_csv('feature_selected_cicids2017.csv')\n",
    "\n",
    "qt = QuantileTransformer(random_state=10) # number of quantiles can be set, default n_quantiles=1000\n",
    "\n",
    "labels = dfv3.loc[:, \"Label\"]\n",
    "\n",
    "binary_labels = dfv3.loc[:, \"Traffic type\"]\n",
    "\n",
    "dfv3.drop([\"Label\", \"Traffic type\"], axis=1, inplace=True) # drop categorical columns\n",
    "\n",
    "dfv3_scalled = qt.fit_transform(dfv3)\n",
    "\n",
    "dfv3_scalled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "BENIGN              280308\n",
      "DoS Hulk             96802\n",
      "DDoS                 71851\n",
      "PortScan             50862\n",
      "DoS GoldenEye         5717\n",
      "FTP-Patator           3299\n",
      "DoS slowloris         3013\n",
      "DoS Slowhttptest      2942\n",
      "SSH-Patator           1816\n",
      "Bot                   1079\n",
      "Brute Force            800\n",
      "XSS                    376\n",
      "Infiltration            20\n",
      "Sql Injection           12\n",
      "Heartbleed               5\n",
      "Name: count, dtype: int64\n",
      "Total: 518902\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels  = train_test_split(dfv3_scalled, labels, random_state=10, train_size=0.7) # 70/30 train test split\n",
    "train_features, validation_features, train_labels, validation_labels = train_test_split(train_features, train_labels, random_state=10, train_size=0.8)\n",
    "\n",
    "labels_count = train_labels.value_counts()\n",
    "all_samples = labels_count.sum()\n",
    "print(labels_count)\n",
    "print(\"Total: {}\".format(all_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_86939/2569048250.py:69: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_features = pd.concat([pd.DataFrame(over_features), replicated_features], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampled Training Labels Distribution:\n",
      "BENIGN              280308\n",
      "DoS Hulk             96802\n",
      "DDoS                 71851\n",
      "PortScan             50862\n",
      "DoS GoldenEye         5717\n",
      "FTP-Patator           3299\n",
      "DoS slowloris         3013\n",
      "DoS Slowhttptest      2942\n",
      "SSH-Patator           2595\n",
      "Brute Force           2595\n",
      "Bot                   2595\n",
      "XSS                   2595\n",
      "Sql Injection         2595\n",
      "Infiltration          2595\n",
      "Heartbleed            2595\n",
      "Name: count, dtype: int64\n",
      "Oversampled Validation Labels Distribution:\n",
      "Label\n",
      "BENIGN              70305\n",
      "DoS Hulk            24154\n",
      "DDoS                17932\n",
      "PortScan            12559\n",
      "DoS GoldenEye        1420\n",
      "FTP-Patator           831\n",
      "DoS slowloris         757\n",
      "DoS Slowhttptest      723\n",
      "Brute Force           649\n",
      "SSH-Patator           649\n",
      "Bot                   649\n",
      "XSS                   649\n",
      "Infiltration          649\n",
      "Sql Injection         649\n",
      "Heartbleed              3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Parameters\n",
    "min_threshold = 0.005  # Minimum percentage threshold for resampling\n",
    "min_samples_small_class = 2  # Minimum samples required for small classes\n",
    "\n",
    "# Ensure DataFrame/Series compatibility\n",
    "def ensure_dataframe(features, labels):\n",
    "    if isinstance(features, np.ndarray):\n",
    "        features = pd.DataFrame(features)\n",
    "    if isinstance(labels, np.ndarray):\n",
    "        labels = pd.Series(labels)\n",
    "    return features.reset_index(drop=True), labels.reset_index(drop=True)\n",
    "\n",
    "# Handle small classes separately\n",
    "def replicate_small_classes(features, labels, min_samples=2):\n",
    "    features, labels = ensure_dataframe(features, labels)\n",
    "    small_classes = labels.value_counts()[labels.value_counts() < min_samples].index\n",
    "    replicated_features, replicated_labels = [], []\n",
    "    for cls in small_classes:\n",
    "        cls_features = features[labels == cls]\n",
    "        cls_labels = labels[labels == cls]\n",
    "        replicated_features.append(resample(cls_features, replace=True, n_samples=min_samples, random_state=10))\n",
    "        replicated_labels.append(resample(cls_labels, replace=True, n_samples=min_samples, random_state=10))\n",
    "    if replicated_features:\n",
    "        replicated_features = pd.concat(replicated_features, ignore_index=True)\n",
    "        replicated_labels = pd.concat(replicated_labels, ignore_index=True)\n",
    "    else:\n",
    "        replicated_features = pd.DataFrame(columns=features.columns)\n",
    "        replicated_labels = pd.Series(dtype=labels.dtype)\n",
    "    return replicated_features, replicated_labels\n",
    "\n",
    "# Main oversampling function\n",
    "def oversample_data(features, labels):\n",
    "    features, labels = ensure_dataframe(features, labels)\n",
    "    labels_count = labels.value_counts()\n",
    "    all_samples = labels_count.sum()\n",
    "\n",
    "    # Handle classes with fewer than `min_samples_small_class`\n",
    "    small_classes = labels_count[labels_count < min_samples_small_class].index\n",
    "    small_features = features[labels.isin(small_classes)]\n",
    "    small_labels = labels[labels.isin(small_classes)]\n",
    "    replicated_features, replicated_labels = replicate_small_classes(small_features, small_labels, min_samples=min_samples_small_class)\n",
    "\n",
    "    # Determine valid k_neighbors dynamically for SMOTE\n",
    "    smallest_majority_class_size = labels_count[labels_count >= min_samples_small_class].min()\n",
    "    k_neighbors = max(1, min(5, smallest_majority_class_size - 1))  # SMOTE requires k_neighbors < samples in class\n",
    "\n",
    "    # Create SMOTE sampling strategy\n",
    "    smote_strategy = {\n",
    "        cls: max(count, ceil(min_threshold * all_samples))\n",
    "        for cls, count in labels_count.items()\n",
    "        if count >= min_samples_small_class\n",
    "    }\n",
    "\n",
    "    # Apply SMOTE\n",
    "    smote = SMOTE(random_state=10, k_neighbors=k_neighbors, sampling_strategy=smote_strategy)\n",
    "    try:\n",
    "        over_features, over_labels = smote.fit_resample(features, labels)\n",
    "    except ValueError as e:\n",
    "        print(f\"SMOTE failed with ValueError: {e}\")\n",
    "        return features, labels  # Return original data if SMOTE fails\n",
    "\n",
    "    # Combine SMOTE results with small classes\n",
    "    final_features = pd.concat([pd.DataFrame(over_features), replicated_features], ignore_index=True)\n",
    "    final_labels = pd.concat([pd.Series(over_labels), replicated_labels], ignore_index=True)\n",
    "\n",
    "    return final_features, final_labels\n",
    "\n",
    "# Apply oversampling\n",
    "over_train_features, over_train_labels = oversample_data(train_features, train_labels)\n",
    "over_validation_features, over_validation_labels = oversample_data(validation_features, validation_labels)\n",
    "\n",
    "# Print results\n",
    "print(\"Oversampled Training Labels Distribution:\")\n",
    "print(over_train_labels.value_counts())\n",
    "print(\"Oversampled Validation Labels Distribution:\")\n",
    "print(over_validation_labels.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train features (532959, 36)\n",
      "Shape of validation features (132578, 36)\n",
      "Shape of test features (277984, 36)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "test_labels_rshped = test_labels.values.reshape(-1,1)\n",
    "over_train_labels_rshped = over_train_labels.values.reshape(-1,1)\n",
    "over_validation_rshped = over_validation_labels.values.reshape(-1,1)\n",
    "\n",
    "ohenc = OneHotEncoder()\n",
    "\n",
    "\n",
    "test_labels_enc = ohenc.fit_transform(test_labels_rshped).toarray()  # one-hot encoded test set lbls\n",
    "over_train_labels_enc = ohenc.fit_transform(over_train_labels_rshped).toarray()  # one-hot encoded upsampled train set lbls\n",
    "over_validation_labels_enc = ohenc.fit_transform(over_validation_rshped).toarray()  # one-hot encoded upsampled train set lbls for neural nets predicting upsampled traffic\n",
    "\n",
    "print(\"Shape of train features\", over_train_features.shape)\n",
    "print(\"Shape of validation features\", over_validation_features.shape)\n",
    "print(\"Shape of test features\", test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7734616603056313\n",
      "Test Accuracy: 0.7896173880511108\n",
      "Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.99      0.84    150258\n",
      "           1       0.00      0.00      0.00       602\n",
      "           2       0.00      0.00      0.00       459\n",
      "           3       0.96      0.63      0.76     38231\n",
      "           4       0.00      0.00      0.00      3149\n",
      "           5       0.96      0.89      0.92     51890\n",
      "           6       0.00      0.00      0.00      1563\n",
      "           7       0.00      0.00      0.00      1615\n",
      "           8       0.00      0.00      0.00      1801\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       0.00      0.00      0.00        10\n",
      "          11       0.88      0.01      0.03     27273\n",
      "          12       0.00      0.00      0.00       926\n",
      "          13       0.00      0.00      0.00         5\n",
      "          14       0.00      0.00      0.00       197\n",
      "\n",
      "    accuracy                           0.79    277984\n",
      "   macro avg       0.23      0.17      0.17    277984\n",
      "weighted avg       0.79      0.79      0.73    277984\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernardorv/CIC-IDS2017-Data-Mining/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/bernardorv/CIC-IDS2017-Data-Mining/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/bernardorv/CIC-IDS2017-Data-Mining/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['adaboost_multiclass_model.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input shape for the data\n",
    "num_classes = over_train_labels_enc.shape[1]  # Number of classes\n",
    "\n",
    "# Convert one-hot encoded labels back to categorical for AdaBoost\n",
    "train_labels_categorical = np.argmax(over_train_labels_enc, axis=1)\n",
    "validation_labels_categorical = np.argmax(over_validation_labels_enc, axis=1)\n",
    "test_labels_categorical = np.argmax(test_labels_enc, axis=1)\n",
    "\n",
    "# Create an AdaBoost classifier\n",
    "adaboost_model = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=50,  # Number of boosting rounds\n",
    "    learning_rate=1.0,\n",
    "    random_state=10\n",
    ")\n",
    "\n",
    "# Train the AdaBoost model\n",
    "adaboost_model.fit(over_train_features, train_labels_categorical)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "validation_predictions = adaboost_model.predict(over_validation_features)\n",
    "validation_accuracy = accuracy_score(validation_labels_categorical, validation_predictions)\n",
    "print(f\"Validation Accuracy: {validation_accuracy}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_predictions = adaboost_model.predict(test_features)\n",
    "test_accuracy = accuracy_score(test_labels_categorical, test_predictions)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report on Test Data:\")\n",
    "print(classification_report(test_labels_categorical, test_predictions))\n",
    "\n",
    "# Save the AdaBoost model\n",
    "import joblib\n",
    "joblib.dump(adaboost_model, 'adaboost_multiclass_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
